<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2020-02-10 Mon 18:32 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Computer Science For The Busy Developer</title>
<meta name="generator" content="Org mode" />
<link rel="stylesheet" type="text/css" href="assets/style.css" />
<link href="//fonts.googleapis.com/css?family=Open+Sans:300,400,600,700" rel="stylesheet" type="text/css">
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<div id="outline-container-org0596ae1" class="outline-2">
<h2 id="org0596ae1"><span class="section-number-2">1</span> Lower bounds for sorting. Big Omega (\(\Omega\))</h2>
<div class="outline-text-2" id="text-1">
<p>
Generally speaking, for sorting, \(\mathcal{O}(n^{2})\) complexity is not great. Quadratic function grows very fast. Before exploring an alternative, better sorting algorithm, it makes sense to investigate the lower bounds for sorting. What is the best possible time complexity we can dream of?
</p>

<p>
Of course, ideally, we want all algorithms to be \(\mathcal{O}(1)\) â€” constant time. Which means that the algorithm yields correct solution in the same amount for time for any possible input. Note that this doesn't necessarily mean "fast". It could be that it takes trillions of operations and billions of years on a real computer, but the point is that it takes that much for any input, regardless of size. Let's see what the real lower bound is.
</p>

<p>
Bubble sort and other canonical algorithms are comparison-based: they compare pairs of elements in order to determine their relative position. As a result, the algorithm must output a permutation (rearrangement) of the input. For a collection of \(n\) elements, there are \(n!\) distinct permutations (recall the way permutations are calculated in "Faithsort and Bogosort"). For each of these permutations, there exists an input for which that permutation is the only correct answer. For example, the permutation \([a_{4}, a_{1}, a_{3}, a_{2}]\) is the only correct answer for the input \([9, 2, 7, 5]\). In fact, there exists a bijection (1-to-1 mapping) between different orderings of \(n\) distinct elements and the permutations needed to sort them. Give this, we can fix a set of \(n!\) inputs, one for each of \(n!\) output permutations.
</p>

<p>
Initially, the comparison-based sorting algorithm "knows" of \(n!\) possible correct permutations. In the end, it needs to settle on the one correct permutation. We can view the algorithm "travelling" from the first state to the last state, narrowing down the set of permutations all the way to one. The narrowing happens due to comparisons; each new comparison reduces the space of possible solutions. So, the computation can be thought of as a series of YES/NO questions, which yields a binary search tree. The root of the tree corresponds to the initial state of \(n!\) possible correct permutations, before any YES/NO questions is answered. One leaf of the tree corresponds to the correct permutation. For each possible input of size \(n\), there is a "correct leaf".
</p>

<figure><img src="https://s3.amazonaws.com/thinkific/file_uploads/146581/images/4c6/a5e/21f/Decision_tree_comparison_search.png">
<figcaption>Portion of a binary decision tree for a comparison-based sorting algorithm.</figcaption>
</figure>

<p>
Let \(S\) be the set of inputs that are consistent with the answers to comparisons made so far. Initially, \(|S| = n!\). Each comparison splits \(S\) into two groups: those inputs for which the answer is YES and those for which the answer is NO. Each comparison cuts down the size of \(S\) by at most a factor of 2. Since initially the size of \(S\) is \(n!\), and in the end it should be reduced to 1 (one correct solution), the algorithm must make \(log_{2}(n!)\) comparisons.
</p>

<p>
Since we're looking for a lower bound, Big O notation doesn't apply. For this, Big Omega (\(\Omega\)) is used. Similar to Big O, Big Omega is a way to say that some function \(g(n)\) is always "lower" than the function in question.
</p>

<figure><img style="max-width: 400px !important;" src="https://s3.amazonaws.com/thinkific/file_uploads/146581/images/f94/565/c9e/Big_Omega.png">
<figcaption>Graphs of f(n) and g(n).</figcaption>
</figure>

<p>
\[ log_{2}(n!) = log_{2}(n) + log_{2}(n-1) \textrm{ + ... + } log_{2}(2) \]
\[ = \Omega(n log_{2}n) \]
</p>

<p>
Because \(log_{2}n\) is so frequent in computer science, number 2 is usually omitted and only \(logn\) is written. So, the lower bound for any comparison-based sorting algorithm is \(\Omega(n logn)\).
</p>

<p>
Heapsort and Mergesort sorting algorithms have an upper bound of \(\mathcal{O}(nlogn)\) steps. Therefore, they are optimal, as their upper bound is the same as the lower bound for any comparison-based sorting algorithm.</p>
</div>
</div>
</div>
</body>
</html>
